## A) Installation

### Cluster erstellen

##### master:

`microk8s add-node`

Dann bekommt man einen Output wie folgendes:
`microk8s join 172.31.64.100:25000/ba230c4967e67d6e2e87de4dd02a9135/c0514c5cf4fb`

Dieser Befehl muss dann im Node 1 ausgeführt werden.

Das gleiche für Node 2 machen.

Danach zur Überprüfung im master `microk8s kubectl get no` oder `microk8s kubectl get nodes` (beides macht das Gleiche) ausführen.

![image](https://github.com/user-attachments/assets/7cf97f3b-2d72-4a64-a217-af76ff4251da)


## B) Verständnis für Cluster 

#### `microk8s kubectl get nodes` in einem zweiten Node ausführen.

Das Gleiche passiert:

![image](https://github.com/user-attachments/assets/2de557d0-001c-44ff-9527-3acf74c86729)

#### `microk8s status` aufrufen

![image](https://github.com/user-attachments/assets/ce148bfb-b02e-44ea-80c2-917efb0969b6)

Der Befehl `microk8s status` zeigt den Zustand des Clusters.

* `microk8s is running` bedeutet: MicroK8s läuft korrekt auf diesem Server.

* `high-availability: yes` zeigt, dass High Availability aktiviert ist. Das passiert automatisch, wenn drei oder mehr Server im Cluster sind.

* `datastore master nodes:` zeigt die Server, die wichtige Daten des Clusters speichern. Diese Server sichern, dass das System auch funktioniert, wenn einer davon ausfällt.

* `datastore standby nodes:` ist hier leer. Es gibt also keine Reserve-Server, die im Notfall einspringen.


#### Node vom Cluster enfernen

Im Node, was man entfernen will: `microk8s leave`

![image](https://github.com/user-attachments/assets/df09f770-76c9-4dbc-b4d2-b82a44d65bd5)


Auf dem Master (oder anderem verbleibenden Node): `microk8s remove-node <IP--DES-NODES>`

In meinem Fall: `microk8s remove-node 172-31-64-102`

![image](https://github.com/user-attachments/assets/7f51d698-9d07-4a82-b55a-dd0a66680414)


#### Node wieder hinzufügen (als Worker)

![image](https://github.com/user-attachments/assets/0bc2648c-21c4-4d91-8279-f783b39f18c5)

#### nochmals `microk8s status`

![image](https://github.com/user-attachments/assets/355a88f5-3455-4768-8b65-76ab3da0fe93)


##### Unterschied zur vorherigen Anzeige:
Vorher (mit 3 normalen Nodes) stand dort:
high-availability: yes und es gab 3 master nodes.

##### Warum dieser Unterschied?
Ein Worker-Node nimmt nicht am Control Plane teil, also er hilft nicht bei der Verwaltung des Clusters. Deshalb zählt er nicht zur High Availability.
Für High Availability braucht man mindestens 3 Control-Plane-Nodes (also normale, keine Worker).

-> Jetzt gibt es nur noch einen Master, deshalb ist high-availability: no.


#### nochmals `microk8s kubectl get nodes`

##### master
![image](https://github.com/user-attachments/assets/f4d7fdc2-fe0d-4352-857e-92bb5f880da7)

##### worker
![image](https://github.com/user-attachments/assets/c948f677-bb61-494b-a461-21fb41385135)

Der Worker-Node (ip-172-31-64-102) zeigt keine Node-Liste an, weil er nicht Teil der Control Plane ist. Das passt zum microk8s status, der zeigt, dass nur ein Master-Node (Control Plane) vorhanden ist – nur dort kann man den Cluster-Status vollständig abfragen.


#### Unterschied `microk8s` und `microk8s kubectl`

microk8s ist das Hauptprogramm, mit dem man MicroK8s startet, stoppt und verwaltet (z.B. Status anzeigen)

microk8s kubectl ist ein spezieller Befehl innerhalb von MicroK8s, mit dem man den Kubernetes-Cluster selbst steuert (z.B. Nodes anzeigen). Es funktioniert wie das normale kubectl, aber ist in MicroK8s integriert.


